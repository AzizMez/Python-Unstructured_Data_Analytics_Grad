---
title: "Final Report: Dumb Laws vs. Fake Laws"
author: "Aziz Al Mezraani"
output: github_document
---

## Introduction

   We have all read some really dumb laws in our time, but have you ever heard of a law that states
that you can't take a lion to the movies? Well, in Baltimore, Maryland, it is illegal to take a lion to the movies.
This is just one of the many dumb laws that are or were on the books in the United States. We have also experienced the
new found power of text generation through gpts. Knowing these two facts, I decided to create a fun little minigame
called Dumb Laws vs Fake Laws. The game is simple, I will provide you with a law and you have to guess if it is a real
law or a fake law generated by a GPT 4.0 model.

## Finding Real Dumb Laws

   The sites I wanted to use are currently down, but luckily there was a pdf that had a compilation of previous and
current dumb laws for the states of the US.  I will be using this pdf to create a dataframe for the Real Laws. In the
pdf each law id preceded by a bullet point so that is how I will split it.

```{python}
#| eval: false
import pandas as pd
from pypdf import PdfReader
import re
# PDF to DF conversion
reader = PdfReader('C:\\Users\\azizm\\Downloads\\Strange-State-Laws.pdf')

print(len(reader.pages))

page = reader.pages[0]
text = page.extract_text().replace('\n', ' ')
bullet_points = text.split('\u2022')

all_bullet_points = []
for i in range(len(reader.pages)):
    page = reader.pages[i]
    text = page.extract_text().replace('\n', ' ')
    bullet_points = text.split('\u2022')
    all_bullet_points.extend(bullet_points)

with open('C:\\Users\\azizm\\Downloads\\Strange-State-Laws.txt', 'w', encoding='utf-8') as f:
    for point in all_bullet_points:
        f.write(point + '\n')

df = pd.DataFrame(all_bullet_points, columns=['Laws'])

```

## Data Cleaning

   After converting the data into a dataframe, we notice that there are some useless columns, state names mixed with
laws and  city names also mixed with laws. So I had to go through rigorous cleaning to get the data in a format that
will hopefully maximize the effectiveness of the gpt generation of the fake Laws.

```{python}
#| eval: false
## Creating State Column
states = ["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida",
"Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland",
"Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire",
"New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania",
"Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia",
"Washington", "West Virginia", "Wisconsin", "Wyoming"]

def extract_state(text):
    for state in states:
        if text.strip().endswith(state + ":"):
            return state
    return None


df["state_marker"] = df["Laws"].apply(extract_state)

df["state"] = df["state_marker"].shift(1).ffill()

df.drop(columns=["state_marker"], inplace=True)

## Removing Unnecessary Rows

df_filtered = df[~df["Laws"].str.contains(r"\b(Copyright|text)\b", case=False, na=False)]


## Creating City Column
def extract_city(text):
    match = re.match(r"^([\w\s]+):\s*(.*)", text)
    if match:
        city_candidate = match.group(1).strip()
        if len(city_candidate.split()) <= 4:  # Ensure city name is at most 4 words
            return city_candidate, match.group(2)  # Extract city name and remaining text
    return None, text  # If no match or more than 4 words, return None for city

cities = []
cleaned_texts = []

for text in df_filtered["Laws"]:
    city, cleaned_text = extract_city(text)
    cities.append(city)
    cleaned_texts.append(cleaned_text)

df_filtered["City"] = cities
df_filtered["Laws"] = cleaned_texts
df_filtered["City"] = df_filtered["City"].str.strip()

# Cleaning Law Columns
df_filtered["Laws"] = df_filtered["Laws"].str.split(r"\s{4,}").str[0]
df_filtered["Laws"] = df_filtered["Laws"].str.strip()
df_filtered["Laws"] = df_filtered["Laws"].str.replace(r"\s+", " ", regex=True).str.strip()

print(df_filtered.to_string(index=False))

```

## Generating Fake Laws

   Now that we have the real laws in an organized dataframe, we can use them to generate fake laws. I will be using the
GPT-4 model from the OpenAI API to generate the fake laws based on the real laws. Unfortunately, due to it using an API
key that costs money I will be removing my key from the code that would generate the fake laws. The number of fake laws
generated ended up being a bit less than the number of real laws due to monetary restrictions. I already spent $11 on
this project and I am not trying to spend more. However it is a close enough split for the game to show both types of
laws during my presentation.

```{python}
#| eval: false
from haystack import Pipeline
from haystack.components.converters.csv import CSVToDocument
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.builders import PromptBuilder
from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder
from haystack.components.generators import OpenAIGenerator
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
from haystack.utils import Secret

df_real = pd.read_csv("C:\\Users\\azizm\\Documents\\Uni\\Spring 2025\\UDA\\Dumb_Laws.csv")
df_real["Type"] = "Real"
num_laws = 11
converter = CSVToDocument()
results = converter.run(sources=["C:\\Users\\azizm\\Documents\\Uni\\Spring 2025\\UDA\\Dumb_Laws.csv"])
documents = results["documents"]

document_store = InMemoryDocumentStore()
doc_embedder = SentenceTransformersDocumentEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
doc_embedder.warm_up()
docs_with_embeddings = doc_embedder.run(documents)
document_store.write_documents(docs_with_embeddings["documents"])

text_embedder = SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2")
retriever = InMemoryEmbeddingRetriever(document_store)

template = """
Given the following information, answer the question.

Context:
{% for document in documents %}
    {{ document.content }}
{% endfor %}
    Task: {{task}}
    Answer:
"""
# template = """
# Given the following laws, generate a similar but fake law. Ensure that each fake law is unique, varies in location, and is believable within the context of unusual U.S. laws.
#
# Context:
# {% for document in documents %}
#     - State: {{ document.meta['State'] }}
#     - City: {{ document.meta['City'] if document.meta['City'] != 'NA' else 'N/A' }}
#     - Law: {{ document.content }}
# {% endfor %}
#
# Generate a unique fake strange law for a different U.S. state.
# Answer:
# """

prompt_builder = PromptBuilder(template=template)
key = ''
generator = OpenAIGenerator(api_key=Secret.from_token(key),
  model="gpt-4o",
  generation_kwargs={"temperature": 0.7, "max_tokens": 1000, "n": num_laws}
)

basic_rag_pipeline = Pipeline()
basic_rag_pipeline.add_component("text_embedder", text_embedder)
basic_rag_pipeline.add_component("retriever", retriever)
basic_rag_pipeline.add_component("prompt_builder", prompt_builder)
basic_rag_pipeline.add_component("llm", generator)

basic_rag_pipeline.connect("text_embedder.embedding", "retriever.query_embedding")
basic_rag_pipeline.connect("retriever", "prompt_builder.documents")
basic_rag_pipeline.connect("prompt_builder", "llm")

task = "Generate and plainly state unique fake strange laws for different U.S. states based on the real laws given"

response = basic_rag_pipeline.run({"text_embedder": {"text": task},
                                   "prompt_builder": {"task": task}})

fake_laws = response["llm"]["replies"]
df_fake_laws = pd.DataFrame({"State": "N/A", "City": "N/A", "Law": fake_laws, "Type": "Fake"})
df_fake_laws.to_csv("C:\\Users\\azizm\\Documents\\Uni\\Spring 2025\\UDA\\fake_laws.csv", index=False)
```

## Cleaning Fake Laws and Concatenating with Real Laws

   Now that we have the fake laws dataframe, we need to clean it so that it has the same format as the real laws.
That way we can just concatenate them with the real ones really easily and have the final dataset that will be used for
the minigame.

```{python}
#| eval: false
df_fake = pd.read_csv("C:\\Users\\azizm\\Documents\\Uni\\Spring 2025\\UDA\\fake_laws.csv")
df_fake["Law"] = df_fake["Law"].str.split(r"\.")  # Split at every period
df_fake = df_fake.explode("Law").reset_index(drop=True)  # Explode into new rows
df_fake = df_fake[df_fake["Law"].str.len() >= 10].reset_index(drop=True)
df_fake["State"] = df_fake["Law"].str.extract(r"^(.*?):")  # Extract text before :
df_fake["Law"] = df_fake["Law"].str.replace(r"^.*?:", "", regex=True)  # Extract text before :
df_fake["State"] = df_fake["State"].str.replace(r"\*", "", regex=True).str.strip()
df_fake["Law"] = df_fake["Law"].str.replace(r"\*", "", regex=True).str.strip()
df_fake["Law"] = df_fake["Law"].str.replace(r"\s+", " ", regex=True).str.strip()
df_fake["State"] = df_fake["State"].str.replace(r"\s+", " ", regex=True).str.strip()
df_fake["Law"] = df_fake["Law"].str.replace(r"\s+", " ", regex=True).str.strip()
df_fake["Type"] = df_fake["Type"].str.replace(r"\s+", " ", regex=True).str.strip()
df_real = df_real.drop(df_real.columns[0], axis=1)
df_real.info()
df_final = pd.concat([df_real.rename(columns={"Laws": "Law"}), df_fake.rename(columns={"State": "state"})],
                      ignore_index=True)
print(df_final)

```

## Minigame

   Now that we have the final dataframe, we can create the minigame that will allow the user to guess if the law is real
or fake. The user will be given a score as the game goes on until all the laws have been guessed or the user decides to
stop. It will be created using streamlit.

```{python}

# # Streamlit game
import streamlit as st

df_final = pd.read_csv("final_laws_dataset.csv") 
df_game = df_final

import qrcode
import pandas as pd
import requests
from PIL import Image
from io import BytesIO
import time

# Google Form & Sheet URLs (for QR Code Implementation for Presentation)
FORM_URL = "https://docs.google.com/forms/d/e/1FAIpQLSdB7exmWrMhwhjufAwubY4HRTad4HSjG55tTLZJoCwCyVz4ng/viewform"
SHEET_URL = "https://docs.google.com/spreadsheets/d/11NEGdpRFubObmm66fraGt74AtVpI4g4YI3LadBVHgN4/gviz/tq?tqx=out:csv"

df_game = df_final.sample(frac=1).reset_index(drop=True)

if "score" not in st.session_state:
    st.session_state.score = 0
if "current_index" not in st.session_state:
    st.session_state.current_index = 0
if "reveal_location" not in st.session_state:
    st.session_state.reveal_location = False

st.title("Dumb Law or Fake Dumb Law?")
st.subheader("Can you guess if the law is real or fake?")

if "current_law" not in st.session_state:
    st.session_state.current_law = df_game.iloc[st.session_state.current_index]

current_law = st.session_state.current_law

st.write(f"**Law:** {current_law['Law']}")


#Including Scoring System and Live Results of Voting
col1, col2, col3 = st.columns([1, 1, 2])

# Voting Buttons
with col1:
    if st.button("Real"):
        if not st.session_state.reveal_location:
            st.session_state.reveal_location = True
            if current_law["Type"] == "Real":
                st.success("Correct! This law is real.")
                st.session_state.score += 1
            else:
                st.error("Wrong! This law is fake.")

with col2:
    if st.button("Fake"):
        if not st.session_state.reveal_location:
            st.session_state.reveal_location = True
            if current_law["Type"] == "Fake":
                st.success("Correct! This law is fake.")
                st.session_state.score += 1
            else:
                st.error("Wrong! This law is real.")

# Live Results
with col3:
    st.subheader("Live Results")

    def fetch_votes():
        try:
            df_votes = pd.read_csv(SHEET_URL)
            real_votes = df_votes[df_votes.iloc[:, 1] == "Real"].shape[0]
            fake_votes = df_votes[df_votes.iloc[:, 1] == "Fake"].shape[0]
            return real_votes, fake_votes
        except Exception:
            return None, None

    if st.button("Update Live Results"):
        real_votes, fake_votes = fetch_votes()

        if real_votes is not None and fake_votes is not None:
            st.write(f"**Real Votes:** {real_votes}")
            st.write(f"**Fake Votes:** {fake_votes}")
        else:
            st.error("Failed to fetch voting results. Make sure the sheet is public.")

# Show location after if Law is Real
if st.session_state.reveal_location:
    if current_law["Type"] == "Real":
        city = current_law["City"] if pd.notna(current_law["City"]) and current_law["City"].strip() else None
        location_display = f"{city}, {current_law['state']}" if city else current_law["state"]
        st.write(f"**Location:** {location_display}")

    if st.button("Next Law"):
        st.session_state.current_index += 1
        st.session_state.current_law = df_game.iloc[st.session_state.current_index]  # Load new law
        st.session_state.reveal_location = False
        st.rerun()


st.write(f"**Score:** {st.session_state.score}")


if st.session_state.current_index >= len(df_game):
    st.write("Game Over!")
    if st.button("Play Again"):
        st.session_state.current_index = 0
        st.session_state.score = 0
        st.session_state.reveal_location = False
        st.rerun()

```

## QR Code

   Since my presentation during class will be an interactive one, I wanted to create a way for people to vote on whether
the law is real or fake during my presentation. I decided to use a google form and sheet to collect the votes. I will be
creating a QR code that will take the user to the google form. They are allowed to vote multiple times (allowing them to
vote for each law that pops up). In the sheet there is a button integrated to reset the live voting that I will be
manually clicking after each law to see the voting per law. For the live voting to work, I had to integrate part of the
code into the streamlit code. The rest of it is below.

```{python}
# QR Code
st.subheader("Scan the QR Code to Vote")
qr = qrcode.make(FORM_URL)

# Making it fit on the same page (no scrolling)
qr_bytes = BytesIO()
qr.thumbnail((150, 150))
qr.save(qr_bytes, format="PNG")
qr_bytes.seek(0)
st.image(qr_bytes, caption="Scan to Vote!", width=150)
```

## Discussion/Conclusion

   This was a fun project that I enjoyed working on. I learned a lot about the power of GPT-4 and how it can be used to
generate text. I also learned how to use streamlit to create a fun little minigame. It was crazy to see some of the real
laws and how hard it was to distinguish between the two. This furthered showed during my presentations with the splits
of the votes and when the majority was wrong. Moreover, it was my first time presenting something like this, it was a
nice change and it was surprising how many ties I felt awkward even though noone else in the room seemed to feel the
same way. I hope you enjoyed my interactive presentation. I am happy I did something fun as I may not get another chance
to do so in the future. Finally, thanks for another wonderful semester, and you know what comes next.
